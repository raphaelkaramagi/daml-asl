{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ba03c8-3b0f-492f-9331-8f1dbc8df4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a17e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/asl_alphabet_train/asl_alphabet_train'\n",
    "OUTPUT_FILE = '../data/asl_landmarks_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0517a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe will be initialized in parallel workers...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 is intentionally empty for parallel processing\n",
    "# MediaPipe is initialized inside each worker process (in landmark_processor.py)\n",
    "print(\"MediaPipe will be initialized in parallel workers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccac8577-3025-41e2-b9ff-769cd5e0b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86912 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label in sorted(os.listdir(DATA_DIR)):\n",
    "    class_dir = os.path.join(DATA_DIR, label)\n",
    "    \n",
    "    if os.path.isdir(class_dir):\n",
    "        for image_file in os.listdir(class_dir):\n",
    "            if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_paths.append(os.path.join(class_dir, image_file))\n",
    "                labels.append(label)\n",
    "\n",
    "print(f\"Found {len(image_paths)} images belonging to {len(set(labels))} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149dcb36-8056-4052-949d-3d1b489715d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PARALLEL processing with thread-local models...\n",
      "Using 14 threads (each with its own MediaPipe model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765051449.236872 2014818 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "I0000 00:00:1765051449.241112 2014833 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.245516 2014821 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.248552 2014848 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.248816 2014836 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.254411 2014824 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.257098 2014863 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.259782 2014851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.262672 2014837 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.265994 2014866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.267509 2014851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.273254 2014866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.274942 2014878 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "I0000 00:00:1765051449.279578 2014893 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.283512 2014887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.287697 2014908 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.289668 2014896 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.292649 2014909 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.295111 2014891 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.303487 2014911 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.305719 2014897 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.306931 2014925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.311161 2014938 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.316670 2014912 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.320247 2014939 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.321595 2014944 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.321745 2014931 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.326968 2014968 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.337998 2014955 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.342929 2014969 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.344707 2014943 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.350616 2014983 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.355886 2014957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.361633 2014977 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.368419 2014987 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.368704 2014999 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.379320 2015017 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.382001 2014986 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1765051449.383132 2014998 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4 Pro\n",
      "W0000 00:00:1765051449.390630 2015015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.393765 2015000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765051449.400707 2015008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e149e5ca49413d8f7130487719518f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting landmarks:   0%|          | 0/86912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 86912 images.\n",
      "   Successful: 63616 (73.20%)\n",
      "   Failed: 23296 (26.80%)\n",
      "\n",
      "Saving landmarks to CSV...\n",
      "✓ Saved to ../data/asl_landmarks_train.csv\n",
      "✓ CSV shape: (86912, 64)\n",
      "✓ Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "# PARALLEL PROCESSING with ThreadPoolExecutor + Thread-Local MediaPipe\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import mediapipe as mp_module\n",
    "\n",
    "# Thread-local storage - each thread gets its own MediaPipe model\n",
    "thread_local = threading.local()\n",
    "\n",
    "def get_hands_model():\n",
    "    \"\"\"Get or create a MediaPipe Hands model for the current thread\"\"\"\n",
    "    if not hasattr(thread_local, 'hands_model'):\n",
    "        mp_hands = mp_module.solutions.hands\n",
    "        thread_local.hands_model = mp_hands.Hands(\n",
    "            static_image_mode=True,\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "    return thread_local.hands_model\n",
    "\n",
    "def process_single_image(file_path):\n",
    "    \"\"\"Process one image using thread-local MediaPipe model\"\"\"\n",
    "    try:\n",
    "        # Get this thread's own MediaPipe model\n",
    "        hands_model = get_hands_model()\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            return [np.nan] * 63\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands_model.process(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            wrist_coords = hand_landmarks.landmark[0]\n",
    "\n",
    "            landmark_row = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                relative_x = landmark.x - wrist_coords.x\n",
    "                relative_y = landmark.y - wrist_coords.y\n",
    "                relative_z = landmark.z - wrist_coords.z\n",
    "                landmark_row.extend([relative_x, relative_y, relative_z])\n",
    "            return landmark_row\n",
    "        else:\n",
    "            return [np.nan] * 63\n",
    "    except Exception as e:\n",
    "        return [np.nan] * 63\n",
    "\n",
    "# Run with ThreadPoolExecutor\n",
    "print(\"Starting PARALLEL processing with thread-local models...\")\n",
    "num_workers = os.cpu_count()\n",
    "print(f\"Using {num_workers} threads (each with its own MediaPipe model)\")\n",
    "\n",
    "processed_data = []\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_single_image, path): i for i, path in enumerate(image_paths)}\n",
    "    \n",
    "    # Collect results with progress bar\n",
    "    for future in tqdm(as_completed(futures), total=len(image_paths), desc=\"Extracting landmarks\"):\n",
    "        idx = futures[future]\n",
    "        processed_data.append((idx, future.result()))\n",
    "\n",
    "# Sort by original index (as_completed returns in completion order)\n",
    "processed_data.sort(key=lambda x: x[0])\n",
    "processed_data = [x[1] for x in processed_data]\n",
    "\n",
    "# Statistics\n",
    "successful_count = sum(1 for row in processed_data if not np.isnan(row[0]))\n",
    "failed_count = len(processed_data) - successful_count\n",
    "\n",
    "print(f\"\\nProcessed {len(processed_data)} images.\")\n",
    "print(f\"   Successful: {successful_count} ({successful_count/len(processed_data)*100:.2f}%)\")\n",
    "print(f\"   Failed: {failed_count} ({failed_count/len(processed_data)*100:.2f}%)\")\n",
    "\n",
    "# Save to CSV\n",
    "print(\"\\nSaving landmarks to CSV...\")\n",
    "column_names = [f'landmark_{i}_{coord}' for i in range(21) for coord in ['x', 'y', 'z']]\n",
    "df = pd.DataFrame(processed_data, columns=column_names)\n",
    "df['label'] = labels\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✓ Saved to {OUTPUT_FILE}\")\n",
    "print(f\"✓ CSV shape: {df.shape}\")\n",
    "print(f\"✓ Classes: {sorted(df['label'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde061ee-e861-4c30-b405-8783ffafdb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7875e-5115-46fe-96ea-02c522666b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b89a3-d4db-43d8-be9b-3aa5c7539a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741933f1-28ed-4211-bdf6-5a01ce0b3539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
