{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad5ce74",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0237dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce363df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and validation datasets...\n",
      "Found 86912 files belonging to 29 classes.\n",
      "Using 69530 files for training.\n",
      "Found 86912 files belonging to 29 classes.\n",
      "Using 17382 files for validation.\n",
      "Found 29 classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets; identical to notebook 01\n",
    "DATA_DIR = '../data/asl_alphabet_train/asl_alphabet_train'\n",
    "TEST_DATA_DIR = '../data/asl_alphabet_test/asl_alphabet_test'\n",
    "\n",
    "IMAGE_SIZE = (96, 96)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 123\n",
    "NUM_CLASSES = 29  # A-Z, del, nothing, space\n",
    "\n",
    "print(\"Loading training and validation datasets...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc54087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining augmentation and normalization layers...\n",
      "Applying processing and optimizing datasets...\n",
      "Data processing pipeline complete and optimized.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization\n",
    "print(\"Defining augmentation and normalization layers...\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\"\n",
    ")\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "# Apply augmentation to training data, normalization to both\n",
    "print(\"Applying processing and optimizing datasets...\")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"Data processing pipeline complete and optimized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6836de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "  Number of layers: 175\n",
      "  Total parameters: 23,587,712\n",
      "  Trainable layers: 0\n"
     ]
    }
   ],
   "source": [
    "#Loading in ResNet50 and then freezing (not changing the weights) of the base model\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',     \n",
    "    include_top=False,        \n",
    "    input_shape=(96, 96, 3)  \n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "print(f\"  Number of layers: {len(base_model.layers)}\")\n",
    "print(f\"  Total parameters: {base_model.count_params():,}\")\n",
    "print(f\"  Trainable layers: {sum([1 for layer in base_model.layers if layer.trainable])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09a0298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"asl_resnet50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"asl_resnet50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚    \u001b[38;5;34m23,587,712\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m262,272\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚         \u001b[38;5;34m3,741\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,853,725</span> (90.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,853,725\u001b[0m (90.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,013</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,013\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Running images through the base model\n",
    "inputs = keras.Input(shape=(96, 96, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs, name='asl_resnet50')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81360902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the model for training\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399a99d",
   "metadata": {},
   "source": [
    "## Phase 1: Training New Layers (Base Model Frozen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa314843",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    #Early stopping to save time\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    #Slowing down learning rate when stuck\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Saving best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_asl_resnet50_phase1.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e892dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0604 - loss: 3.3253\n",
      "Epoch 1: val_accuracy improved from None to 0.15625, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 106ms/step - accuracy: 0.0815 - loss: 3.2458 - val_accuracy: 0.1563 - val_loss: 2.9772 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1156 - loss: 3.0876\n",
      "Epoch 2: val_accuracy improved from 0.15625 to 0.19952, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 101ms/step - accuracy: 0.1217 - loss: 3.0595 - val_accuracy: 0.1995 - val_loss: 2.7860 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1395 - loss: 2.9896\n",
      "Epoch 3: val_accuracy improved from 0.19952 to 0.21637, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 106ms/step - accuracy: 0.1384 - loss: 2.9806 - val_accuracy: 0.2164 - val_loss: 2.6945 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1467 - loss: 2.9443\n",
      "Epoch 4: val_accuracy improved from 0.21637 to 0.23559, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 109ms/step - accuracy: 0.1480 - loss: 2.9364 - val_accuracy: 0.2356 - val_loss: 2.6333 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1524 - loss: 2.9113\n",
      "Epoch 5: val_accuracy improved from 0.23559 to 0.25319, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 111ms/step - accuracy: 0.1536 - loss: 2.9038 - val_accuracy: 0.2532 - val_loss: 2.5831 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.1589 - loss: 2.8822\n",
      "Epoch 6: val_accuracy improved from 0.25319 to 0.25641, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 105ms/step - accuracy: 0.1594 - loss: 2.8799 - val_accuracy: 0.2564 - val_loss: 2.5786 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1630 - loss: 2.8602\n",
      "Epoch 7: val_accuracy did not improve from 0.25641\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 100ms/step - accuracy: 0.1633 - loss: 2.8623 - val_accuracy: 0.2554 - val_loss: 2.5454 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1688 - loss: 2.8444\n",
      "Epoch 8: val_accuracy did not improve from 0.25641\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 100ms/step - accuracy: 0.1667 - loss: 2.8462 - val_accuracy: 0.2550 - val_loss: 2.5074 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1670 - loss: 2.8363\n",
      "Epoch 9: val_accuracy improved from 0.25641 to 0.25935, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 101ms/step - accuracy: 0.1680 - loss: 2.8353 - val_accuracy: 0.2593 - val_loss: 2.4927 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1744 - loss: 2.8203\n",
      "Epoch 10: val_accuracy improved from 0.25935 to 0.26424, saving model to best_asl_resnet50_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 100ms/step - accuracy: 0.1735 - loss: 2.8222 - val_accuracy: 0.2642 - val_loss: 2.4864 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "#Training the new layers\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd694715",
   "metadata": {},
   "source": [
    "## Phase 2: Fine-Tuning Entire Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9403ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters now: 15,242,013\n"
     ]
    }
   ],
   "source": [
    "#Unfreezing the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),  # 10x lower LR\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Total trainable parameters now: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "188f18ba-c170-46e8-8ffb-d9060810c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING PHASE 2 FINE-TUNING\n",
      "============================================================\n",
      "Trainable parameters: 15,242,013\n",
      "This will take approximately 30-60 minutes...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1147 - loss: 4.1229\n",
      "Epoch 1: val_accuracy improved from None to 0.28760, saving model to best_asl_resnet50_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 194ms/step - accuracy: 0.1616 - loss: 3.0791 - val_accuracy: 0.2876 - val_loss: 2.4233 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.2551 - loss: 2.5059\n",
      "Epoch 2: val_accuracy improved from 0.28760 to 0.37982, saving model to best_asl_resnet50_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 189ms/step - accuracy: 0.2697 - loss: 2.4399 - val_accuracy: 0.3798 - val_loss: 2.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3121 - loss: 2.2684\n",
      "Epoch 3: val_accuracy did not improve from 0.37982\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 197ms/step - accuracy: 0.3204 - loss: 2.2283 - val_accuracy: 0.3570 - val_loss: 2.0954 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3502 - loss: 2.1100\n",
      "Epoch 4: val_accuracy did not improve from 0.37982\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 194ms/step - accuracy: 0.3603 - loss: 2.0715 - val_accuracy: 0.3194 - val_loss: 2.7869 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3937 - loss: 1.9533\n",
      "Epoch 5: val_accuracy improved from 0.37982 to 0.39455, saving model to best_asl_resnet50_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 191ms/step - accuracy: 0.4029 - loss: 1.9209 - val_accuracy: 0.3945 - val_loss: 1.9186 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.4330 - loss: 1.8087\n",
      "Epoch 6: val_accuracy improved from 0.39455 to 0.42130, saving model to best_asl_resnet50_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 192ms/step - accuracy: 0.4427 - loss: 1.7732 - val_accuracy: 0.4213 - val_loss: 2.4739 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4714 - loss: 1.6725\n",
      "Epoch 7: val_accuracy improved from 0.42130 to 0.48061, saving model to best_asl_resnet50_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 194ms/step - accuracy: 0.4790 - loss: 1.6436 - val_accuracy: 0.4806 - val_loss: 1.7146 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5088 - loss: 1.5451\n",
      "Epoch 8: val_accuracy did not improve from 0.48061\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 195ms/step - accuracy: 0.5164 - loss: 1.5221 - val_accuracy: 0.3921 - val_loss: 2.1988 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5402 - loss: 1.4395\n",
      "Epoch 9: val_accuracy did not improve from 0.48061\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 193ms/step - accuracy: 0.5469 - loss: 1.4175 - val_accuracy: 0.4228 - val_loss: 2.3608 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5706 - loss: 1.3409\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.48061\n",
      "\u001b[1m2173/2173\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 191ms/step - accuracy: 0.5747 - loss: 1.3242 - val_accuracy: 0.4724 - val_loss: 1.8604 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "============================================================\n",
      "âœ“ PHASE 2 FINE-TUNING COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STARTING PHASE 2 FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")\n",
    "print(\"This will take approximately 30-60 minutes...\")\n",
    "print()\n",
    "\n",
    "# Setup callbacks for Phase 2\n",
    "callbacks_list_phase2 = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_asl_resnet50_phase2.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# FIXED: Train Phase 2 properly (NO initial_epoch!)\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,  \n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list_phase2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ PHASE 2 FINE-TUNING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733fb87",
   "metadata": {},
   "source": [
    "## Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aefdffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                    TRAINING RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š PHASE 1: Frozen Base Model (COMPLETED)\n",
      "----------------------------------------------------------------------\n",
      "  Final Training Accuracy:    0.1735 (17.35%)\n",
      "  Final Validation Accuracy:  0.2642 (26.42%)\n",
      "  Final Training Loss:        2.8222\n",
      "  Final Validation Loss:      2.4864\n",
      "  Epochs Trained:             10\n",
      "\n",
      "ğŸ“Š PHASE 2: Fine-Tuned Model (COMPLETED)\n",
      "----------------------------------------------------------------------\n",
      "  Final Training Accuracy:    0.5747 (57.47%)\n",
      "  Final Validation Accuracy:  0.4724 (47.24%)\n",
      "  Final Training Loss:        1.3242\n",
      "  Final Validation Loss:      1.8604\n",
      "  Epochs Trained:             10\n",
      "\n",
      "ğŸ¯ IMPROVEMENT\n",
      "----------------------------------------------------------------------\n",
      "  Validation Accuracy Gain:   +20.82%\n",
      "  (From 26.42% â†’ 47.24%)\n",
      "\n",
      "======================================================================\n",
      "âœ“ TRAINING PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display comprehensive results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*20 + \"TRAINING RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“Š PHASE 1: Frozen Base Model (COMPLETED)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Final Training Accuracy:    {history_phase1.history['accuracy'][-1]:.4f} ({history_phase1.history['accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Final Validation Accuracy:  {history_phase1.history['val_accuracy'][-1]:.4f} ({history_phase1.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Final Training Loss:        {history_phase1.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Final Validation Loss:      {history_phase1.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Epochs Trained:             {len(history_phase1.epoch)}\")\n",
    "\n",
    "print(\"\\nğŸ“Š PHASE 2: Fine-Tuned Model (COMPLETED)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Final Training Accuracy:    {history_phase2.history['accuracy'][-1]:.4f} ({history_phase2.history['accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Final Validation Accuracy:  {history_phase2.history['val_accuracy'][-1]:.4f} ({history_phase2.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Final Training Loss:        {history_phase2.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Final Validation Loss:      {history_phase2.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Epochs Trained:             {len(history_phase2.epoch)}\")\n",
    "\n",
    "# Calculate improvement\n",
    "phase1_val_acc = history_phase1.history['val_accuracy'][-1]\n",
    "phase2_val_acc = history_phase2.history['val_accuracy'][-1]\n",
    "improvement = (phase2_val_acc - phase1_val_acc) * 100\n",
    "\n",
    "print(\"\\nğŸ¯ IMPROVEMENT\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Validation Accuracy Gain:   +{improvement:.2f}%\")\n",
    "print(f\"  (From {phase1_val_acc*100:.2f}% â†’ {phase2_val_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ TRAINING PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c772d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Final model saved as 'asl_resnet50_final.keras'\n",
      "\n",
      "ğŸ“ Final Model Inventory:\n",
      "------------------------------------------------------------\n",
      "  âœ“ best_asl_resnet50_phase1.h5              (  93.4 MB)\n",
      "  âœ“ best_asl_resnet50_phase2.h5              ( 207.7 MB)\n",
      "  âœ“ asl_resnet50_final.keras                 ( 207.9 MB)\n",
      "\n",
      "âœ“ All done! Ready for evaluation in Notebook 07.\n"
     ]
    }
   ],
   "source": [
    "# Save the final trained model\n",
    "model.save('asl_resnet50_final.keras')\n",
    "print(\"âœ“ Final model saved as 'asl_resnet50_final.keras'\")\n",
    "\n",
    "# Verify all models\n",
    "print(\"\\nğŸ“ Final Model Inventory:\")\n",
    "print(\"-\" * 60)\n",
    "for filename in ['best_asl_resnet50_phase1.h5', \n",
    "                 'best_asl_resnet50_phase2.h5',\n",
    "                 'asl_resnet50_final.keras']:\n",
    "    if os.path.exists(filename):\n",
    "        size_mb = os.path.getsize(filename) / (1024*1024)\n",
    "        print(f\"  âœ“ {filename:40s} ({size_mb:>6.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  âœ— {filename:40s} (NOT FOUND)\")\n",
    "\n",
    "print(\"\\nâœ“ All done! Ready for evaluation in Notebook 07.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479789a-62d0-4a73-aaa1-49f6ced7c293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa249c25-66cd-4dcb-a317-1a4dcf31ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c631e-00e3-4899-8cef-4bffbb9cd02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
