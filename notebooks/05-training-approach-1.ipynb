{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad5ce74",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0237dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce363df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and validation datasets...\n",
      "Found 86912 files belonging to 29 classes.\n",
      "Using 69530 files for training.\n",
      "Found 86912 files belonging to 29 classes.\n",
      "Using 17382 files for validation.\n",
      "Found 29 classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets; identical to notebook 01\n",
    "DATA_DIR = '../data/asl_alphabet_train/asl_alphabet_train'\n",
    "TEST_DATA_DIR = '../data/asl_alphabet_test/asl_alphabet_test'\n",
    "\n",
    "IMAGE_SIZE = (96, 96)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 123\n",
    "NUM_CLASSES = 29  # A-Z, del, nothing, space\n",
    "\n",
    "print(\"Loading training and validation datasets...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc54087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining augmentation and normalization layers...\n",
      "Applying processing and optimizing datasets...\n",
      "Data processing pipeline complete and optimized.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization\n",
    "print(\"Defining augmentation and normalization layers...\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\"\n",
    ")\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "# Apply augmentation to training data, normalization to both\n",
    "print(\"Applying processing and optimizing datasets...\")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"Data processing pipeline complete and optimized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6836de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "  Number of layers: 175\n",
      "  Total parameters: 23,587,712\n",
      "  Trainable layers: 0\n"
     ]
    }
   ],
   "source": [
    "#Loading in ResNet50 and then freezing (not changing the weights) of the base model\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',     \n",
    "    include_top=False,        \n",
    "    input_shape=(96, 96, 3)  \n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "print(f\"  Number of layers: {len(base_model.layers)}\")\n",
    "print(f\"  Total parameters: {base_model.count_params():,}\")\n",
    "print(f\"  Trainable layers: {sum([1 for layer in base_model.layers if layer.trainable])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09a0298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"asl_resnet50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"asl_resnet50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m3,741\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,853,725</span> (90.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,853,725\u001b[0m (90.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,013</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,013\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Running images through the base model\n",
    "inputs = keras.Input(shape=(96, 96, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs, name='asl_resnet50')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81360902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the model for training\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399a99d",
   "metadata": {},
   "source": [
    "## Phase 1: Training New Layers (Base Model Frozen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa314843",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    #Early stopping to save time\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    #Slowing down learning rate when stuck\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Saving best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_asl_resnet50_phase1.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e892dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1183/2173\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 85ms/step - accuracy: 0.0493 - loss: 3.3643"
     ]
    }
   ],
   "source": [
    "#Training the new layers\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd694715",
   "metadata": {},
   "source": [
    "## Phase 2: Fine-Tuning Entire Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9403ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreezing the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),  # 10x lower LR\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Total trainable parameters now: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b25aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating callbacks for Phase 2\n",
    "callbacks_list_phase2 = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_asl_resnet50_phase2.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,  \n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list_phase2,\n",
    "    verbose=1,\n",
    "    initial_epoch=len(history_phase1.epoch) \n",
    ")\n",
    "\n",
    "print(\"\\nFine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733fb87",
   "metadata": {},
   "source": [
    "## Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training histories\n",
    "def combine_histories(h1, h2):\n",
    "    \"\"\"Combine two training histories\"\"\"\n",
    "    combined = {}\n",
    "    for key in h1.keys():\n",
    "        combined[key] = h1[key] + h2[key]\n",
    "    return combined\n",
    "\n",
    "history = combine_histories(history_phase1.history, history_phase2.history)\n",
    "\n",
    "# Print final metrics \n",
    "# Phase 1 results\n",
    "print(\"\\nPhase 1 (Frozen Base Model):\")\n",
    "print(f\"  Training Accuracy: {history_phase1.history['accuracy'][-1]:.4f} ({history_phase1.history['accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Validation Accuracy: {history_phase1.history['val_accuracy'][-1]:.4f} ({history_phase1.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Training Loss: {history_phase1.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Loss: {history_phase1.history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "# Phase 2 results\n",
    "print(\"\\nPhase 2 (Fine-Tuned Model):\")\n",
    "print(f\"  Training Accuracy: {history_phase2.history['accuracy'][-1]:.4f} ({history_phase2.history['accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Validation Accuracy: {history_phase2.history['val_accuracy'][-1]:.4f} ({history_phase2.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"  Training Loss: {history_phase2.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Loss: {history_phase2.history['val_loss'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c772d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('asl_resnet50_final.h5')\n",
    "print(\"Model saved as 'asl_resnet50_final.h5'\")\n",
    "\n",
    "# Also save the best model if it exists\n",
    "if os.path.exists('best_asl_resnet50_phase2.h5'):\n",
    "    print(\"Best model (from checkpoint) saved as 'best_asl_resnet50_phase2.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479789a-62d0-4a73-aaa1-49f6ced7c293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa249c25-66cd-4dcb-a317-1a4dcf31ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c631e-00e3-4899-8cef-4bffbb9cd02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
